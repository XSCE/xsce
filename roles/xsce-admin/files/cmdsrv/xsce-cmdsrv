#!/usr/bin/python

"""

   XSCE Multi-threaded Polling Command server

   Author: Tim Moody <tim(at)timmoody(dot)com>
   Contributions: Guillaume Aubert (gaubert) <guillaume(dot)aubert(at)gmail(dot)com>
                 Felipe Cruz <felipecruz@loogica.net>

   Accepts commands in the form COMMAND <optional json-encoded arguments>
   Returns json-encoded results

"""

import os, sys, syslog
import pwd, grp
import time
from datetime import date, datetime
import threading, subprocess
import shlex
import zmq
import sqlite3
import json
import yaml
import re

# Config Files
xsce_config_file = "/etc/xsce/xsce.env"
xsce_cmdsrv_config_file = "/etc/xsce/cmdsrv.conf"

# Variables that should be read from config file
# All of these variables will be read from config files and recomputed in init()
xsce_git_path = "/root/xsce"
xsce_base_path = "/opt/schoolserver"

cmdsrv_no_workers = 5
cmdsrv_job_poll_sleep_interval = 1
cmdsrv_max_concurrent_jobs = 7

# Derived Variables
xsce_cmdsrv_path = xsce_base_path + "/xsce_cmdsrv"
xsce_cmdsrv_pid_file = "/var/run/xsce-cmdsrv.pid"
xsce_cmdsrv_dbname = xsce_cmdsrv_path + "/xsce_cmdsrv.db"

# Constants - ToDo add to xsce_cmdsrv_config_file
squid_whitelist = "/etc/squid/sites.whitelist.txt"

# Global Variables
last_command_rowid = 0
last_job_rowid = 0

jobs_requested = {}
jobs_running = {}

ansible_running_flag = False

# vars read from ansible vars directory
# effective is composite where local takes precedence

default_vars = {}
local_vars = {}
effective_vars = {}
ansible_facts = {}
ansible_tags = {}

# vars set by admin-console
config_vars = {}

# available commands are in cmd_handler

def tprint(msg):
    """like print, but won't get newlines confused with multiple threads DELETE AFTER TESTING"""
    sys.stdout.write(msg + '\n')
    sys.stdout.flush()

def main():
    """Server routine"""

    init()
    worker_data_url = "inproc://worker_data"
    worker_control_url = "inproc://worker_control"
    ipc_sock = "/run/cmdsrv_sock"
    client_url = "ipc://" + ipc_sock

    owner = pwd.getpwnam("apache")
    group = grp.getgrnam("xsce-admin")

    # Prepare our context and sockets
    context = zmq.Context.instance()

    # Socket to talk to clients
    clients = context.socket(zmq.ROUTER)
    clients.bind(client_url)
    os.chown(ipc_sock, owner.pw_uid, group.gr_gid)
    os.chmod(ipc_sock, 0770)

    # Socket to talk to workers
    workers_data = context.socket(zmq.DEALER)
    workers_data.bind(worker_data_url)
    workers_control = context.socket(zmq.PUB)
    workers_control.bind(worker_control_url)

    # Launch thread to monitor jobs
    thread = threading.Thread(target=job_minder_thread, args=(client_url, worker_control_url,))
    thread.start()

    # Launch pool of worker threads
    for i in range(cmdsrv_no_workers):
        thread = threading.Thread(target=cmd_proc_thread, args=(worker_data_url, worker_control_url,))
        thread.start()


    poll = zmq.Poller()
    poll.register(clients, zmq.POLLIN)
    poll.register(workers_data, zmq.POLLIN)

    server_run = True

    while server_run == True:
        sockets = dict(poll.poll())
        if clients in sockets:
            ident, msg = clients.recv_multipart()
            tprint('sending message server received from client to worker %s id %s' % (msg, ident))
            if msg == "STOP":
                # Tell the worker threads to shut down
                tprint('sending control message server received from client to worker %s id %s' % (msg, ident))
                workers_control.send("EXIT")
                clients.send_multipart([ident, '{"Status": "Stopping"}'])
                log(syslog.LOG_NOTICE, 'Stopping XSCE Command Server')
                time.sleep(3)
                server_run = False
            else:
                tprint('sending data message server received from client to worker %s id %s' % (msg, ident))
                workers_data.send_multipart([ident, msg])
        if workers_data in sockets:
            ident, msg = workers_data.recv_multipart()
            tprint('Sending worker message to client %s id %s' % (msg[:60], ident))
            clients.send_multipart([ident, msg])

    # Clean up if server is stopped
    clients.close()
    workers_data.close()
    workers_control.close()
    context.term()

    # Delete any pid file to keep systemd happy
    try:
        os.remove(xsce_cmdsrv_pid_file)
    except OSError:
        pass

    sys.exit()

def job_minder_thread(client_url, worker_control_url, context=None):
    """Job Monitoring Worker Routine"""

    global jobs_requested
    global jobs_running
    global ansible_running_flag

    print "in job_minder_thread"

    jobs_requested_done = {}
    jobs_to_close = {}

    # control signals from main thread
    context = context or zmq.Context.instance()
    control_socket = context.socket(zmq.SUB)
    control_socket.connect(worker_control_url)
    control_socket.setsockopt(zmq.SUBSCRIBE,"")

    # Socket to send job status back to main
    resp_socket = context.socket(zmq.DEALER)
    resp_socket.connect(client_url)

    poll = zmq.Poller()
    poll.register(control_socket, zmq.POLLIN)

    thread_run = True

    while thread_run == True:
        # start any requested jobs
        for key in jobs_requested:
            job_id = key
            job_info = jobs_requested[key]

            # don't create ansible job if one is running
            if job_info['cmd'] == "RUN-ANSIBLE" and ansible_running_flag == True:
                continue
            # tried to change buffer size to get line by line output, but no luck
            job_info['output_file'] = '/tmp/job-' + str(key)
            #job_info['file'] = open(job_info['output_file'], 'w', buffering=1)
            job_info['file'] = open(job_info['output_file'], 'w')
            #job_info['cmd'] = jobs_requested[key]
            args = shlex.split(job_info['job_command'])
            job_info['subproc'] = subprocess.Popen(args, stdout=job_info['file'], stderr=subprocess.STDOUT)
            #job_info['subproc'] = subprocess.Popen(args, bufsize=1, stdout=job_info['file'], stderr=subprocess.STDOUT)
            job_info['job_pid'] = job_info['subproc'].pid
            job_info['status'] = 'STARTED'
            job_info['status_datetime'] = str(datetime.now())
            job_info['job_output'] = ""

            if job_info['cmd'] == "RUN-ANSIBLE":
                ansible_running_flag = True
            log(syslog.LOG_NOTICE, "Starting Job: %s, pid: %s" % (job_info['cmd'], job_info['job_pid']))

            # update jobs table
            upd_job_started(job_id, job_info['job_pid'])
            jobs_running[key] = job_info
            jobs_requested_done[key] = True

        print 'starting clear'
        # clear started jobs from requested queue
        for key in jobs_requested_done:
            jobs_requested.pop(key, None)
        jobs_pending_done = {}

        print 'starting poll'
        # poll jobs_running for completed jobs
        for key in jobs_running:
            job_id = key
            jobs_running[key]['subproc'].poll()
            returncode = jobs_running[key]['subproc'].returncode
            if returncode == None:
                print str(key) + ' still running.'
            else:
                print str(key) + ' terminated.'
                jobs_running[key]['file'].close()

                # load output from tmp file
                output_file = jobs_running[key]['output_file']
                file = open(output_file, 'r')
                job_output = file.read()
                jobs_running[key]['job_output'] = job_output
                file.close()

                job_info['status_datetime'] = str(datetime.now())
                if returncode == 0:
                    jobs_running[key]['status'] = 'SUCCEEDED'
                else:
                    jobs_running[key]['status'] = 'FAILED'

                log(syslog.LOG_NOTICE, "Job: %s, pid: %s, status:%s" % (job_info['cmd'], job_info['job_pid'], jobs_running[key]['status']))

                # send status to main
                #resp_socket.send('JOB-STATUS {' + str(key) + ':"Finished"}')
                #resp_socket.recv() # get reply

                # update jobs table and remove tmp output file
                upd_job_finished(job_id, job_output, jobs_running[key]['status'])
                os.remove(output_file)

                if job_info['cmd'] == "RUN-ANSIBLE":
                    ansible_running_flag = False

                # flag job for removal
                jobs_to_close[key] = True

        print 'starting close jobs'
        # now remove closed jobs from running list
        for key in jobs_to_close:
            jobs_running.pop(key, None)

        print 'starting socket poll'
        sockets = dict(poll.poll(1000))
        if control_socket in sockets:
            ctl_msg = control_socket.recv()
            tprint('got ctl msg %s in monitor' % ctl_msg)
            if ctl_msg == "EXIT":
                # stop loop in order to terminate thread
                log(syslog.LOG_NOTICE, 'Stopping XSCE Command Server Monitor Thread')
                thread_run = False

        print 'starting sleep'
        time.sleep(cmdsrv_job_poll_sleep_interval)
        print 'ready to loop'

    # Clean up if thread is stopped
    resp_socket.close()
    control_socket.close()
    #context.term()
    #sys.exit()

def cmd_proc_thread(worker_data_url, worker_control_url, context=None):
    """Command Processing Worker Routine"""
    context = context or zmq.Context.instance()
    # Socket to talk to dispatcher
    data_socket = context.socket(zmq.DEALER)
    data_socket.connect(worker_data_url)

    # control signals from main thread
    control_socket = context.socket(zmq.SUB)
    control_socket.connect(worker_control_url)
    control_socket.setsockopt(zmq.SUBSCRIBE,"")

    poll = zmq.Poller()
    poll.register(data_socket, zmq.POLLIN)
    poll.register(control_socket, zmq.POLLIN)

    thread_run = True

    while thread_run == True:

        sockets = dict(poll.poll())
        # process command
        if data_socket in sockets:
            ident, cmd_msg = data_socket.recv_multipart()
            tprint('sending message server received from client to worker %s id %s' % (cmd_msg, ident))
            cmd_resp = cmd_handler(cmd_msg)
            data_socket.send_multipart([ident, cmd_resp])
        if control_socket in sockets:
            ctl_msg = control_socket.recv()
            tprint('got ctl msg %s in worker' % ctl_msg)
            if ctl_msg == "EXIT":
                # stop loop in order to terminate thread
                log(syslog.LOG_NOTICE, 'Stopping XSCE Command Server Worker Thread')
                thread_run = False

    # Clean up if thread is stopped
    data_socket.close()
    control_socket.close()
    #context.term()
    #sys.exit()

def cmd_handler(cmd_msg):

    # List of recognized commands and corresponding routine
    # Don't do anything else

    avail_cmds = {
        "TEST": do_test,
        "LIST": list_library,
        "WGET": wget_file,
        "GET-ANS": get_ans_facts,
        "GET-ANS-TAGS": get_ans_tags,
        "GET-VARS": get_install_vars,
        "GET-CONF": get_config_vars,
        "SET-CONF": set_config_vars,
        "GET-MEM-INFO": get_mem_info,
        "GET-STORAGE-INFO": get_storage_info,
        "RUN-ANSIBLE": run_ansible,
        "GET-JOB-STAT": get_last_jobs_stat,
        "GET-WHLIST": get_white_list,
        "SET-WHLIST": set_white_list,
        "REBOOT": reboot_server
        }

    # store the command in database
    cmd_rowid = insert_command(cmd_msg)

    # process the command

    cmd_info = {}

    # parse for arguments
    cmd_parts = cmd_msg.split(' ',1)

    cmd = cmd_parts[0]
    if len(cmd_parts)>1:
        try:
            cmd_args = json.loads(cmd_parts[1])
        except:
            return cmd_malformed(cmd)
    else:
        cmd_args = {}

    cmd_info['cmd_rowid'] = cmd_rowid
    cmd_info['cmd'] = cmd
    cmd_info['cmd_args'] = cmd_args

    # commands that run scripts should check for malicious characters in cmd_args and return error if found
    # bad_command = validate_command(cmd_args)

    try:
        resp = avail_cmds[cmd](cmd_info)
    except KeyError, e:
        # print e
        resp = '{"Error": "Unknown Command"}'
    return (resp)

#
# Functions to process Commands
#

def do_test(cmd_info):

    resp = cmd_success("TEST")
    return (resp)

def list_library(cmd_info):
    resp = subprocess.check_output(["scripts/list_libr.sh"])
    json_resp = json_array("library_list", resp)
    return (json_resp)

def wget_file(cmd_info):
    resp = cmd_info['cmd'] + " done."

    return (resp)

def get_ans_facts(cmd_info):
    resp = json.dumps(ansible_facts)
    return (resp)

def get_ans_tags(cmd_info):
    resp = json.dumps(ansible_tags)
    return (resp)

def get_install_vars(cmd_info):
    resp = json.dumps(effective_vars)
    return (resp)

def get_mem_info(cmd_info):
    outp = subprocess.check_output(["/usr/bin/free", "-h"])
    json_outp = json_array("system_memory", outp)
    return (json_outp)

def get_storage_info(cmd_info):
    system_storage = []
    system_disks = {}
    system_disks = get_disk_info()
    #print system_disks
    #outp = subprocess.check_output(["scripts/get_all_free.sh"])
    outp = subprocess.check_output(["scripts/get_stor_devs.sh"])
    dev_arr = outp.split('\n')
    #arr1 = outp.split(';\n\n\r') # trim off quit stuff at the end
    #arr2 = arr1[0].split('BYT;\n') # split into devices
    #dev_arr = arr2[1:]
    for dev_str in dev_arr:
        dev = dev_str.split(" ")[0]
        try:
            parts = subprocess.check_output(["parted", dev, "-ms", "print", "free"])
        except subprocess.CalledProcessError as e:
            #skip devices that cause problems
            print e
            pass
        else:
            blkstr = parts.split("BYT;\n")[1]
            #print "blkstr is " +  blkstr
            dev_info = {}
            dev_blk = blkstr.split(';\n') # dev_blk[0] is the device itself, some can be free space
            dev_char = dev_blk[0]
            dev_attr = dev_char.split(':')
            dev_info['device'] = dev_attr[0]
            dev_info['size'] = dev_attr[1]
            dev_info['type'] = dev_attr[2]
            dev_info['log_sect_size'] = dev_attr[3]
            dev_info['phys_sect_size'] = dev_attr[4]
            dev_info['part_tbl'] = dev_attr[5]
            dev_info['desc'] = dev_attr[6]
            dev_info['blocks'] = []
            dev_blk = dev_blk[1:]
            #print dev_blk
            dev_blk = [a for a in dev_blk if a not in ['\n']]
            for blk in dev_blk: # blocks can be free or partitioned
                #print "blk is " + blk
                if blk == '':
                    continue
                blk_info = {}
                blk_attr = blk.split(':')
                blk_info['part_no'] = blk_attr[0] # is 1 for free
                blk_info['start'] = blk_attr[1]
                blk_info['end'] = blk_attr[2]
                blk_info['size'] = blk_attr[3]
                blk_info['type'] = blk_attr[4]
                if blk_info['type'] == 'free':
                    blk_info['part_dev'] = 'unallocated'
                else:
                    # this is a kluge
                    if "mmc" in dev_info['device']:
                        blk_info['part_dev'] = dev_info['device'] + 'p' + blk_info['part_no']
                    else:
                        blk_info['part_dev'] = dev_info['device'] + blk_info['part_no']
                    #print blk_info['part_dev']
                    blk_info['part_prop'] = system_disks[blk_info['part_dev']]
                if len(blk_attr) == 7:
                    blk_info['flag'] = blk_attr[6]
                else:
                    blk_info['flag'] = ""
                dev_info['blocks'].append(blk_info)
            system_storage.append(dev_info)

    #json_outp = json_array("system_storage", system_storage)
    #resp = json.dumps(system_storage)
    #resp = '{ "system_storage":' + json.dumps(system_storage) + '}'
    resp = json.dumps(system_storage)
    return (resp)

def get_disk_info():
    system_disks = {}
    outp = subprocess.check_output(["/usr/sbin/blkid"])
    str_array = outp.split('\n')
    str_array = [a for a in str_array if a not in ['']]
    for item in str_array:
        disk_info = {}
        item_arr = item.split(': ')
        dev = item_arr[0]
        item_attr_arr = item_arr[1].split(' ')
        for attr in item_attr_arr:
            if attr != "":
                kv = attr.split('=')
                disk_info[kv[0]] = kv[1]
        outp2 = subprocess.check_output(["/usr/bin/df", dev, "-m"])
        str_array2 = outp2.split('\n')
        params = str_array2[1]
        parm_arr = params.split(' ')
        parm_arr = [a for a in parm_arr if a not in ['']]
        disk_info['size_in_megs'] = parm_arr[1]
        disk_info['avail_in_megs'] = parm_arr[3]
        disk_info['mount_point'] = parm_arr[5]
        system_disks[dev] = disk_info
    return (system_disks)

def get_white_list(cmd_info):
    whlist = []
    try:
        stream = open(squid_whitelist, 'r')
        whlist = stream.read()
        stream.close()
    except IOError:
        whlist = []

    #resp = '{"xsce_whitelist": "' + whlist + '"}'
    resp = json_array("xsce_whitelist", whlist)
    return (resp)

def set_white_list(cmd_info):
    whlist = cmd_info['cmd_args']['xsce_whitelist']
    whlist = filter(None, whlist) # remove blank lines
    resp = cmd_success(cmd_info['cmd'])
    try:
        stream =  open(squid_whitelist, 'w')
        for item in whlist:
            stream.write(item + '\n')
    except IOError:
        resp = cmd_error
    finally:
        stream.close()
    return (resp)

def get_config_vars(cmd_info):
    read_config_vars()
    resp = json.dumps(config_vars)
    return (resp)

def set_config_vars(cmd_info):
    global config_vars
    lock = threading.Lock()
    lock.acquire() # will block if lock is already held
    try:
        config_vars = cmd_info['cmd_args']['config_vars']
    finally:
        lock.release() # release lock, no matter what
    write_config_vars()
    #print config_vars
    resp = cmd_success(cmd_info['cmd'])
    return (resp)

def run_ansible(cmd_info):

    global ansible_running_flag
    global jobs_requested

    if ansible_running_flag:
        return ('{"Error": "Ansible Command already Running."}')

    job_command = "/usr/bin/ansible-playbook -i " + xsce_git_path + "/ansible_hosts " + xsce_git_path + "/xsce-from-console.yml --connection=local"

    if 'cmd_args' in cmd_info:
        tags = cmd_info['cmd_args']['tags']
        if tags != "ALL-TAGS":
            job_command += ' --tags="' +  tags +'"'
    else:
        return cmd_malformed(cmd_info['cmd'])

    resp = request_job(cmd_info, job_command)
    return resp

def reboot_server(cmd_info):
    resp = cmd_success(cmd_info['cmd'])
    rc = subprocess.call(["/usr/sbin/reboot"])
    return (resp)

def request_job(cmd_info, job_command, cmd_step_no=1):
    global jobs_requested
    job_id = get_job_id()

    job_info = {}
    job_info['cmd_rowid'] = cmd_info['cmd_rowid']
    job_info['cmd'] = cmd_info['cmd']
    job_info['cmd_args'] = cmd_info['cmd_args']

    job_info['cmd_step_no'] = cmd_step_no
    job_info['job_command'] = job_command
    job_info['status'] = 'SCHEDULED'
    job_info['status_datetime'] = str(datetime.now())

    jobs_requested[job_id] = job_info
    insert_job(job_id, cmd_info['cmd_rowid'], job_command, cmd_step_no)

    return ('{"Success": "Job  ' + str(job_id) + ' Scheduled."}')

def get_last_jobs_stat(cmd_info):
    conn = sqlite3.connect(xsce_cmdsrv_dbname)
    cur = conn.execute ("SELECT rowid, job_command, job_output, job_status, last_update_datetime FROM jobs ORDER BY rowid DESC LIMIT 30")
    last_jobs = cur.fetchall()
    conn.close()

    #print "job running"
    #print jobs_running
    # get status output for incomplete ansible jobs
    last_jobs_cc = []
    for job in last_jobs:
        job_id = job[0]
        if job_id in jobs_running:
            job_cc = []
            job_cc.append(job[0])
            job_cc.append(job[1])
            job_output = job[2]
            if jobs_running[job_id]['cmd'] == "RUN-ANSIBLE" and jobs_running[job_id]['status'] == "STARTED":
                # load output from tmp file
                output_file = jobs_running[job_id]['output_file']
                file = open(output_file, 'r')
                job_output = file.read()
                file.close()
                #print "job output" + job_output

            job_cc.append(job_output)
            job_cc.append(job[3])
            job_cc.append(job[4])

            last_jobs_cc.append(job_cc)
        else:
            last_jobs_cc.append(job)

    #print "last_jobs_cc"
    #print last_jobs_cc
    resp = json.dumps(last_jobs_cc)
    return resp

def get_jobs_running(cmd_info):
    global jobs_running
    today = str(date.today())
    job_stat = {}
    cur_jobs = {}
    for job, job_info in jobs_running.iteritems():
        if today in job_info['status_datetime'] or jobinfo['status'] in ['SCHEDULED','STARTED']:
            job_stat['status'] = job_info['status']
            job_stat['job_command'] = job_info['job_command']
            job_stat['status_datetime'] = job_info['status_datetime']
            job_stat['status_datetime'] = job_info['status_datetime']
            job_stat['job_output'] = job_info['job_output']
            cur_jobs[job] = job_stat

    resp = json.dumps(cur_jobs)
    return resp

def json_array(name, str):
    try:
        str_array = str.split('\n')
        str_json = json.dumps(str_array)
        json_resp = '{ "' + name + '":' + str_json + '}'
    except StandardError:
        json_resp = cmd_error()
    return (json_resp)

def validate_command(cmd):
    match = re.search('[;,|<>()=&\r\n]', cmd, flags=0)
    if match != None:
        return ('{"Error": "Malformed Command."}')
    else:
        return None

def get_cmd_info_key(cmd_info, key):
   if key in cmd_info:
       return (cmd_info[key])
   else:
       return None

def cmd_success(cmd):
   return ('{"Success": "Command ' + cmd + '."}')

def cmd_error(cmd=None):
    return ('{"Error": "Internal Server Error processing Command ' + cmd + '."}')

def cmd_malformed(cmd=None):
    return ('{"Error": "Malformed Command ' + cmd + '."}')

def insert_command(cmd_msg):
    global last_command_rowid
    lock = threading.Lock()
    lock.acquire() # will block if lock is already held
    try:
        cmd_id = last_command_rowid + 1
        last_command_rowid = cmd_id
    finally:
        lock.release() # release lock, no matter what

    now = datetime.now()
    try:
        conn = sqlite3.connect(xsce_cmdsrv_dbname)
        conn.execute ("INSERT INTO commands (rowid, cmd_msg, create_datetime) VALUES (?,?,?)", (cmd_id, cmd_msg, now))
        conn.commit()
        conn.close()

    except sqlite3.Error, e:

        print "Error %s:" % e.args[0]
        log(syslog.LOG_NOTICE, "Sql Lite3 Error %s:" % e.args[0])

    finally:

        if conn:
            conn.close()

    return (cmd_id)

def insert_job(job_id, cmd_rowid, job_command, cmd_step_no=1, job_pid=0, job_output="", job_status="SCHEDULED"):
    #print "in insert job"
    now = datetime.now()

    conn = sqlite3.connect(xsce_cmdsrv_dbname)
    conn.execute ("INSERT INTO jobs (rowid, cmd_rowid, cmd_step_no, job_command, job_pid, job_output, job_status, create_datetime, last_update_datetime) VALUES (?,?,?,?,?,?,?,?,?)",
                  (job_id, cmd_rowid, cmd_step_no, job_command, job_pid, job_output, job_status, now, now))

    conn.commit()
    conn.close()

def upd_job_started(job_id, job_pid, job_status="STARTED"):

    now = datetime.now()

    conn = sqlite3.connect(xsce_cmdsrv_dbname)
    conn.execute ("UPDATE jobs SET job_pid = ?, job_status = ?, last_update_datetime = ? WHERE rowid = ?", (job_pid, job_status, now, job_id))

    conn.commit()
    conn.close()

def upd_job_finished(job_id, job_output, job_status="FINISHED"):

    now = datetime.now()

    conn = sqlite3.connect(xsce_cmdsrv_dbname)
    conn.execute ("UPDATE jobs SET job_status = ?, job_output = ?, last_update_datetime = ? WHERE rowid = ?", (job_status, job_output, now, job_id))

    conn.commit()
    conn.close()

def get_job_id():
    global last_job_rowid
    lock = threading.Lock()
    lock.acquire() # will block if lock is already held
    try:
        job_id = last_job_rowid + 1
        last_job_rowid = job_id
    finally:
        lock.release() # release lock, no matter what

    return(job_id)

def init():
    global last_command_rowid
    global last_job_rowid

    # Read application variables from config files
    app_config()

    # Read vars from ansible file into global vars
    get_xsce_vars()

    # Get ansible facts and tags for localhost
    get_ansible_facts()
    get_ansible_tags()

    # See if queue.db exists and create if not
    # Opening a connection creates if not exist
    if not os.path.isfile(xsce_cmdsrv_dbname):
        conn = sqlite3.connect(xsce_cmdsrv_dbname)
        conn.execute ("CREATE TABLE commands (cmd_msg text, create_datetime text)")
        conn.commit()
        conn.execute ("CREATE TABLE jobs (cmd_rowid integer, cmd_step_no integer, job_command text, job_pid integer, job_output blob, job_status text, create_datetime text, last_update_datetime text)")
        conn.commit()
        conn.close()
    else:
        conn = sqlite3.connect(xsce_cmdsrv_dbname)
        cur = conn.execute("SELECT max (rowid) from commands")
        row = cur.fetchone()
        if row[0] is not None:
            last_command_rowid = row[0]

        cur = conn.execute("SELECT max (rowid) from jobs")
        row = cur.fetchone()
        if row[0] is not None:
            last_job_rowid = row[0]

        cur.close()
        conn.close()

def read_config_vars():
    global config_vars

    stream = open("/etc/xsce/config_vars.yml", 'r')
    config_vars = yaml.load(stream)
    stream.close()
    if config_vars == None:
        config_vars = {} # try to make the ajax call happy

def write_config_vars():
    global config_vars

    lock = threading.Lock()
    lock.acquire() # will block if lock is already held

    try:
        stream =  open("/etc/xsce/config_vars.yml", 'w')
        stream.write('# DO NOT MODIFY THIS FILE.\n')
        stream.write('# IT IS AUTOMATICALLY GENERATED.\n')
        for key in config_vars:
             if isinstance(config_vars[key], (int, float)): # boolean is int
                 value = str(config_vars[key])
             else:
                 value = '"' + config_vars[key] + '"'
             entry = key + ': ' + value
             stream.write(entry + '\n')
        stream.close()
    finally:
        lock.release() # release lock, no matter what

def get_xsce_vars():
    global default_vars
    global local_vars
    global effective_vars

    stream = open(xsce_git_path + "/vars/default_vars.yml", 'r')
    default_vars = yaml.load(stream)
    stream.close()

    stream = open(xsce_git_path + "/vars/local_vars.yml", 'r')
    local_vars = yaml.load(stream)
    stream.close()

    if local_vars == None:
        local_vars = {}

    # combine vars with local taking precedence
    # exclude derived vars marked by {

    for key in default_vars:
        if isinstance(default_vars[key], str):
            findpos = default_vars[key].find("{")
            if findpos == -1:
                effective_vars[key] = default_vars[key]
        else:
            effective_vars[key] = default_vars[key]

    for key in local_vars:
        if isinstance(local_vars[key], str):
            findpos = local_vars[key].find("{")
            if findpos == -1:
                effective_vars[key] = local_vars[key]
        else:
            effective_vars[key] = local_vars[key]

def get_ansible_facts():
    global ansible_facts

    command = "/usr/bin/ansible localhost -i " + xsce_git_path + "/ansible_hosts  -m setup -o  --connection=local"
    args = shlex.split(command)
    outp = subprocess.check_output(args)
    ans_str = outp.split('success >> ')
    ans = json.loads(ans_str[1])
    ansible_facts = ans['ansible_facts']

def get_ansible_tags():
    global ansible_tags

    command = "/usr/bin/ansible-playbook -i " + xsce_git_path + "/ansible_hosts " + xsce_git_path + "/xsce-from-console.yml --connection=local --tags=???"
    args = shlex.split(command)
    try:
        subprocess.check_output(args)
    except subprocess.CalledProcessError as e:
        outp = e.output

    # get just the tag list and remove final newline
    split = outp.split('values: ')
    ans_tags_str = split[1].split('\n')[0]
    ansible_tags['ansible_tags'] = ans_tags_str

def app_config():

    global xsce_cmdsrv_path
    global xsce_cmdsrv_pid_file
    global xsce_cmdsrv_dbname

    # Read variables from xsce config file
    read_xsce_conf_file()
    # Read variables from xsce-cmdsrv config file
    read_xsce_cmdsrv_conf_file()

    # Compute Derived Variables
    xsce_cmdsrv_path = xsce_base_path + "/xsce_cmdsrv"
    xsce_cmdsrv_pid_file = "/var/run/xsce-cmdsrv.pid"
    xsce_cmdsrv_dbname = xsce_cmdsrv_path + "/xsce_cmdsrv.db"

def read_xsce_cmdsrv_conf_file():
    global cmdsrv_no_workers
    global cmdsrv_job_poll_sleep_interval
    global cmdsrv_max_concurrent_jobs

    stream = open (xsce_cmdsrv_config_file,"r")
    inp = json.load(stream)
    stream.close()
    conf = inp['xsce-cmdsrv_conf']

    cmdsrv_no_workers = conf['cmdsrv_no_workers']
    cmdsrv_job_poll_sleep_interval = conf['cmdsrv_job_poll_sleep_interval']
    cmdsrv_max_concurrent_jobs = conf['cmdsrv_max_concurrent_jobs']
    xsce_cmdsrv_pid_file = conf['xsce_cmdsrv_pid_file']

# These two were taken from the OLPC idmgr application

def read_xsce_conf_file():
    global xsce_base_path
    global xsce_git_path

    load_config = {}
    try:
        f = open(xsce_config_file, "r")
        try:
            for line in f:
                line = line.lstrip()
                if line == '' or line.startswith('#'):
                    continue
                k, v = [x.strip() for x in line.split('=', 1)]
                try:
                    v = float(v)
                    v = int(v)
                except ValueError:
                    pass
                if isinstance(v, str):
                    #Maybe it's quoted.
                    for quote in '\'"':
                        if (v.startswith(quote) and v.endswith(quote)
                            and quote not in v[1:-1]):
                            v = v[1:-1]
                            break
                load_config[k] = v
        except IOError:
            load_config = {}
        finally:
            f.close()
    except IOError:
        log(syslog.LOG_NOTICE, 'Error reading XSCE Command Server Config')
    else:
        xsce_base_path = load_config['XSCE_BASE_PATH']
        xsce_git_path = load_config['XSCE_DIR']

def createDaemon(pidfilename):
    """Detach a process from the controlling terminal and run it in the
    background as a daemon.
    """
    pid = os.fork()
    if (pid == 0):   # The first child.
        pid = os.fork()
        if (pid == 0):   # The second child.
            # Since the current working directory may be a mounted filesystem,
            # we avoid the issue of not being able to unmount the filesystem at
            # shutdown time by changing it to the /opt directory where the cmdsrv is installed.
            os.chdir(xsce_cmdsrv_path)
            #os.umask(config.UMASK)
        else:
            #  write out pid of child
            try:
                pidfile = open( pidfilename, "w" );
                pidfile.write( str( pid ) );
                pidfile.write( "\n" );
                pidfile.close();
            except OSError, e:
                syslog.openlog( 'xsce_cmdsrv', 0, syslog.LOG_USER )
                syslog.syslog( syslog.LOG_ALERT, "Writing PID file: %s [%d]" % (e.strerror, e.errno) )
                syslog.closelog()
                raise
            os._exit(0)  # Exit parent (the first child) of the second child.
    else:
        os._exit(0)# Exit parent of the first child.

    # Close all open file descriptors.
    # Use the getrlimit method to retrieve the maximum file descriptor
    # number that can be opened by this process.  If there is not limit
    # on the resource, use the default value.
    #
    import resource     # Resource usage information.
    maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]
    if (maxfd == resource.RLIM_INFINITY):
        maxfd = MAXFD

    # Iterate through and close all file descriptors.
    for fd in range(0, maxfd):
        try:
            os.close(fd)
        except OSError: # ERROR, fd wasn't open to begin with (ignored)
            pass

    # Redirect the standard I/O file descriptors to the specified file.  Since
    # the daemon has no controlling terminal, most daemons redirect stdin,
    # stdout, and stderr to /dev/null.  This is done to prevent side-effects
    # from reads and writes to the standard I/O file descriptors.

    # This call to open is guaranteed to return the lowest file descriptor,
    # which will be 0 (stdin), since it was closed above.
    os.open(os.devnull, os.O_RDWR)    # standard input (0)

    # Duplicate standard input to standard output and standard error.
    os.dup2(0, 1)# standard output (1)
    os.dup2(0, 2)# standard error (2)
    return(0)

# Now start the application

if __name__ == "__main__":

    # do the UNIX double-fork magic if --daemon passed as argument
    if len(sys.argv) > 1:
        if sys.argv[1] in ('--daemon'):
           retCode = createDaemon( xsce_cmdsrv_pid_file )
           #retCode = createDaemon( sys.argv[1] ) # pass pid file
        syslog.openlog( 'xsce_cmdsrv', 0, syslog.LOG_USER )
        log = syslog.syslog
    else:
        def log(*args):
            print >> sys.stderr, args

    log(syslog.LOG_NOTICE, 'Starting XSCE Command Server')

    # Now run the main routine
    main()
