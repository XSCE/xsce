#!/usr/bin/python

"""

   XSCE Multi-threaded Polling Command server

   Author: Tim Moody <tim(at)timmoody(dot)com>
   Contributions: Guillaume Aubert (gaubert) <guillaume(dot)aubert(at)gmail(dot)com>
                 Felipe Cruz <felipecruz@loogica.net>
                 
   Accepts commands in the form COMMAND <optional json-encoded arguments>
   Returns json-encoded results

"""
    
import os, sys, syslog
import pwd, grp
import time
from datetime import date, datetime
import threading, subprocess
import shlex
import zmq
import sqlite3
import json
import yaml
import re

# Config Files
xsce_config_file = "/etc/xsce/xsce.conf"
xsce_cmdsrv_config_file = "/etc/xsce/cmdsrv.conf"

# Variables that should be read from config file
# All of these variables will be read from config files and recomputed in init()
xsce_git_path = "/root/xsce"
xsce_base_path = "/opt/schoolserver"

cmdsrv_no_workers = 5
cmdsrv_job_poll_sleep_interval = 1
cmdsrv_max_concurrent_jobs = 7

# Derived Variables
xsce_cmdsrv_path = xsce_base_path + "/xsce_cmdsrv"
xsce_cmdsrv_pid_file = "/var/run/xsce-cmdsrv.pid"
xsce_cmdsrv_dbname = xsce_cmdsrv_path + "/xsce_cmdsrv.db"

# Constants - ToDo add to xsce_cmdsrv_config_file
squid_whitelist = "/etc/squid/sites.whitelist.txt"

# Global Variables
last_command_rowid = 0
last_job_rowid = 0

jobs_requested = {}
jobs_running = {}

ansible_running_flag = False

# vars read from ansible vars directory
# effective is composite where local takes precedence

default_vars = {}
local_vars = {}
effective_vars = {}
ansible_facts = {}
ansible_tags = {}

# vars set by admin-console
config_vars = {}

# available commands are in cmd_handler

def tprint(msg):
    """like print, but won't get newlines confused with multiple threads DELETE AFTER TESTING"""
    sys.stdout.write(msg + '\n')
    sys.stdout.flush()

def main():
    """Server routine"""
    
    init()
    worker_data_url = "inproc://worker_data"
    worker_control_url = "inproc://worker_control"
    ipc_sock = "/run/cmdsrv_sock"
    client_url = "ipc://" + ipc_sock
    
    owner = pwd.getpwnam("apache")
    group = grp.getgrnam("xsce-admin")

    # Prepare our context and sockets
    context = zmq.Context.instance()

    # Socket to talk to clients
    clients = context.socket(zmq.ROUTER)
    clients.bind(client_url)
    os.chown(ipc_sock, owner.pw_uid, group.gr_gid)
    os.chmod(ipc_sock, 0770)

    # Socket to talk to workers
    workers_data = context.socket(zmq.DEALER)
    workers_data.bind(worker_data_url)
    workers_control = context.socket(zmq.PUB)
    workers_control.bind(worker_control_url)
    
    # Launch thread to monitor jobs
    thread = threading.Thread(target=job_minder_thread, args=(client_url, worker_control_url,))
    thread.start()

    # Launch pool of worker threads
    for i in range(cmdsrv_no_workers):
        thread = threading.Thread(target=cmd_proc_thread, args=(worker_data_url, worker_control_url,))
        thread.start()
        

    poll = zmq.Poller()
    poll.register(clients, zmq.POLLIN)
    poll.register(workers_data, zmq.POLLIN)
    
    server_run = True

    while server_run == True:
        sockets = dict(poll.poll())
        if clients in sockets:
            ident, msg = clients.recv_multipart()
            tprint('sending message server received from client to worker %s id %s' % (msg, ident))
            if msg == "STOP":
                # Tell the worker threads to shut down
                tprint('sending control message server received from client to worker %s id %s' % (msg, ident))
                workers_control.send("EXIT")
                clients.send_multipart([ident, '{"Status": "Stopping"}'])
                log(syslog.LOG_NOTICE, 'Stopping XSCE Command Server')
                time.sleep(3)
                server_run = False
            else:
                tprint('sending data message server received from client to worker %s id %s' % (msg, ident))
                workers_data.send_multipart([ident, msg])
        if workers_data in sockets:
            ident, msg = workers_data.recv_multipart()
            tprint('Sending worker message to client %s id %s' % (msg, ident))
            clients.send_multipart([ident, msg])

    # Clean up if server is stopped
    clients.close()
    workers_data.close()
    workers_control.close()
    context.term()

    # Delete any pid file to keep systemd happy
    try:
        os.remove(xsce_cmdsrv_pid_file)
    except OSError:
        pass

    sys.exit()

def job_minder_thread(client_url, worker_control_url, context=None):
    """Job Monitoring Worker Routine"""
    
    global jobs_requested
    global jobs_running
    global ansible_running_flag
    
    print "in job_minder_thread"
    
    jobs_requested_done = {}
    jobs_to_close = {}
    
    # control signals from main thread
    context = context or zmq.Context.instance()
    control_socket = context.socket(zmq.SUB)
    control_socket.connect(worker_control_url)
    control_socket.setsockopt(zmq.SUBSCRIBE,"")
    
    # Socket to send job status back to main
    resp_socket = context.socket(zmq.DEALER)
    resp_socket.connect(client_url)        
    
    poll = zmq.Poller()
    poll.register(control_socket, zmq.POLLIN)   
    
    thread_run = True
    
    while thread_run == True:        
        # start any requested jobs    
        for key in jobs_requested:
            job_id = key            
            job_info = jobs_requested[key]
            
            # don't create ansible job if one is running
            if job_info['cmd'] == "RUN-ANSIBLE" and ansible_running_flag == True:
                continue             
            
            job_info['output_file'] = '/tmp/job-' + str(key)
            job_info['file'] = open(job_info['output_file'], 'w')
            #job_info['cmd'] = jobs_requested[key]
            args = shlex.split(job_info['job_command'])
            job_info['subproc'] = subprocess.Popen(args, stdout=job_info['file'], stderr=subprocess.STDOUT)
            job_info['job_pid'] = job_info['subproc'].pid 
            job_info['status'] = 'STARTED'
            job_info['status_datetime'] = str(datetime.now())
            job_info['job_output'] = ""
            
            if job_info['cmd'] == "RUN-ANSIBLE":
                ansible_running_flag = True
            
            # update jobs table
            upd_job_started(job_id, job_info['job_pid'])             
            jobs_running[key] = job_info
            jobs_requested_done[key] = True
        
        print 'starting clear'    
        # clear started jobs from requested queue    
        for key in jobs_requested_done:
            jobs_requested.pop(key, None)
        jobs_pending_done = {}
        
        print 'starting poll'
        # poll jobs_running for completed jobs    
        for key in jobs_running:
            job_id = key
            jobs_running[key]['subproc'].poll()
            returncode = jobs_running[key]['subproc'].returncode            
            if returncode == None:
                print str(key) + ' still running.'
            else:           
                print str(key) + ' terminated.'
                jobs_running[key]['file'].close()

                # load output from tmp file
                output_file = jobs_running[key]['output_file']
                file = open(output_file, 'r')               
                job_output = file.read()
                jobs_running[key]['job_output'] = job_output
                file.close()
                                
                job_info['status_datetime'] = str(datetime.now())
                if returncode == 0:
                    jobs_running[key]['status'] = 'SUCCEEDED'
                else:
                    jobs_running[key]['status'] = 'FAILED'   
                # send status to main
                #resp_socket.send('JOB-STATUS {' + str(key) + ':"Finished"}')
                #resp_socket.recv() # get reply
                
                # update jobs table and remove tmp output file
                upd_job_finished(job_id, job_output, jobs_running[key]['status'])
                os.remove(output_file)
                
                if job_info['cmd'] == "RUN-ANSIBLE":
                    ansible_running_flag = False
                
                # flag job for removal
                jobs_to_close[key] = True                
        
        print 'starting close jobs'    
        # now remove closed jobs from running list
        for key in jobs_to_close:            
            jobs_running.pop(key, None)
        
        print 'starting socket poll'
        sockets = dict(poll.poll(1000))
        if control_socket in sockets:
            ctl_msg = control_socket.recv()
            tprint('got ctl msg %s in monitor' % ctl_msg)
            if ctl_msg == "EXIT":
                # stop loop in order to terminate thread 
                log(syslog.LOG_NOTICE, 'Stopping XSCE Command Server Monitor Thread')  
                thread_run = False
        
        print 'starting sleep'        
        time.sleep(cmdsrv_job_poll_sleep_interval)
        print 'ready to loop' 

    # Clean up if thread is stopped
    resp_socket.close()
    control_socket.close()
    #context.term()             
    #sys.exit()          
    
def cmd_proc_thread(worker_data_url, worker_control_url, context=None):
    """Command Processing Worker Routine"""
    context = context or zmq.Context.instance()
    # Socket to talk to dispatcher
    data_socket = context.socket(zmq.DEALER)
    data_socket.connect(worker_data_url)
    
    # control signals from main thread
    control_socket = context.socket(zmq.SUB)
    control_socket.connect(worker_control_url)
    control_socket.setsockopt(zmq.SUBSCRIBE,"")
    
    poll = zmq.Poller()
    poll.register(data_socket, zmq.POLLIN)
    poll.register(control_socket, zmq.POLLIN)   
    
    thread_run = True
    
    while thread_run == True:
    
        sockets = dict(poll.poll())
        # process command
        if data_socket in sockets:
            ident, cmd_msg = data_socket.recv_multipart()
            tprint('sending message server received from client to worker %s id %s' % (cmd_msg, ident))
            cmd_resp = cmd_handler(cmd_msg)
            data_socket.send_multipart([ident, cmd_resp])
        if control_socket in sockets:
            ctl_msg = control_socket.recv()
            tprint('got ctl msg %s in worker' % ctl_msg)
            if ctl_msg == "EXIT":
                # stop loop in order to terminate thread 
                log(syslog.LOG_NOTICE, 'Stopping XSCE Command Server Worker Thread')  
                thread_run = False
                
    # Clean up if thread is stopped
    data_socket.close()
    control_socket.close()
    #context.term()             
    #sys.exit()        

def cmd_handler(cmd_msg):

    # List of recognized commands and corresponding routine
    # Don't do anything else
    
    avail_cmds = {
        "TEST": do_test,
        "LIST": list_library,
        "WGET": wget_file,
        "GET-ANS": get_ans_facts,
        "GET-ANS-TAGS": get_ans_tags,
        "GET-VARS": get_install_vars,
        "GET-CONF": get_config_vars,
        "SET-CONF": set_config_vars,
        "GET-MEM-INFO": get_mem_info,
        "GET-STORAGE-INFO": get_storage_info,
        "RUN-ANSIBLE": run_ansible,
        "GET-JOB-STAT": get_last_jobs_stat,
        "GET-WHLIST": get_white_list,
        "SET-WHLIST": set_white_list,
        "REBOOT": reboot_server
        }             
    
    # store the command in database
    cmd_rowid = insert_command(cmd_msg)
        
    # process the command
    
    cmd_info = {}
    
    # parse for arguments
    cmd_parts = cmd_msg.split(' ',1)

    cmd = cmd_parts[0]    
    if len(cmd_parts)>1:
        try:
            cmd_args = json.loads(cmd_parts[1])
        except:
            return cmd_malformed(cmd)
    else:
        cmd_args = {}
            
    cmd_info['cmd_rowid'] = cmd_rowid
    cmd_info['cmd'] = cmd
    cmd_info['cmd_args'] = cmd_args

    # commands that run scripts should check for malicious characters in cmd_args and return error if found
    # bad_command = validate_command(cmd_args)
    
    try:
        resp = avail_cmds[cmd](cmd_info)
    except KeyError, e:
        # print e
        resp = '{"Error": "Unknown Command"}'        
    return (resp)
    
#
# Functions to process Commands
#

def do_test(cmd_info):
    
    resp = cmd_success("TEST")        
    return (resp)
    
def list_library(cmd_info):
    resp = subprocess.check_output(["scripts/list_libr.sh"])
    json_resp = json_array("library_list", resp)      
    return (json_resp)
    
def wget_file(cmd_info):
    resp = cmd_info['cmd'] + " done."
    
    return (resp)
    
def get_ans_facts(cmd_info):
    resp = json.dumps(ansible_facts)    
    return (resp) 
    
def get_ans_tags(cmd_info):
    resp = json.dumps(ansible_tags)    
    return (resp)       
    
def get_install_vars(cmd_info):
    resp = json.dumps(effective_vars)    
    return (resp)

def get_mem_info(cmd_info):    
    outp = subprocess.check_output(["/usr/bin/free", "-h"])
    json_outp = json_array("system_memory", outp)      
    return (json_outp)    

def get_storage_info(cmd_info):
    system_storage = []
    system_disks = {}
    system_disks = get_disk_info()
    print system_disks                                                                                              
    outp = subprocess.check_output(["scripts/get_all_free.sh"])                                                      
    arr1 = outp.split(';\n\n\r') # trim off quit stuff at the end                                                    
    arr2 = arr1[0].split('BYT;\n') # split into devices                                                              
    dev_arr = arr2[1:]                                                                                               
    for dev_str in dev_arr:                                                                                          
        dev_info = {}                                                                                                
        dev_blk = dev_str.split(';\n') # dev_blk[0] is the device itself, some can be free space
        dev_char = dev_blk[0]
        dev_attr = dev_char.split(':')
        dev_info['device'] = dev_attr[0]
        dev_info['size'] = dev_attr[1]
        dev_info['type'] = dev_attr[2]
        dev_info['log_sect_size'] = dev_attr[3]
        dev_info['phys_sect_size'] = dev_attr[4]
        dev_info['part_tbl'] = dev_attr[5]
        dev_info['desc'] = dev_attr[6]
        dev_info['blocks'] = []
        dev_blk = dev_blk[1:]
        dev_blk = [a for a in dev_blk if a not in ['\n']]                         
        for blk in dev_blk: # blocks can be free or partitioned
            blk_info = {}                                                                                                                                                                                                          
            blk_attr = blk.split(':')        
            blk_info['part_no'] = blk_attr[0] # is 1 for free            
            blk_info['start'] = blk_attr[1]
            blk_info['end'] = blk_attr[2]
            blk_info['size'] = blk_attr[3]
            blk_info['type'] = blk_attr[4]
            if blk_info['type'] == 'free':
                blk_info['part_dev'] = 'unallocated'
            else:
                blk_info['part_dev'] = dev_info['device'] + blk_info['part_no']
                print blk_info['part_dev']
                blk_info['part_prop'] = system_disks[blk_info['part_dev']]
            if len(blk_attr) == 7:
                blk_info['flag'] = blk_attr[6]        
            else:
                blk_info['flag'] = ""
            dev_info['blocks'].append(blk_info)    
        system_storage.append(dev_info)
            
    #json_outp = json_array("system_storage", system_storage)     
    #resp = json.dumps(system_storage)
    #resp = '{ "system_storage":' + json.dumps(system_storage) + '}'
    resp = json.dumps(system_storage)    
    return (resp)
 
def get_disk_info():
    system_disks = {}
    outp = subprocess.check_output(["/usr/sbin/blkid"])
    str_array = outp.split('\n')
    str_array = [a for a in str_array if a not in ['']]
    for item in str_array:
        disk_info = {}
        item_arr = item.split(': ')        
        dev = item_arr[0]
        item_attr_arr = item_arr[1].split(' ')
        for attr in item_attr_arr:
            if attr != "":
                kv = attr.split('=')             
                disk_info[kv[0]] = kv[1]
        outp2 = subprocess.check_output(["/usr/bin/df", dev, "-m"])
        str_array2 = outp2.split('\n')
        params = str_array2[1]
        parm_arr = params.split(' ')
        parm_arr = [a for a in parm_arr if a not in ['']]                                               
        disk_info['size_in_megs'] = parm_arr[1]
        disk_info['avail_in_megs'] = parm_arr[3]
        disk_info['mount_point'] = parm_arr[5]
        system_disks[dev] = disk_info                                                            
    return (system_disks)
           
def get_white_list(cmd_info):
    whlist = []
    try:
        stream = open(squid_whitelist, 'r')
        whlist = stream.read()
    except IOError:
        whlist = []
    finally:        
        stream.close()
    
    #resp = '{"xsce_whitelist": "' + whlist + '"}'    
    resp = json_array("xsce_whitelist", whlist)        
    return (resp)
             
def set_white_list(cmd_info):    
    whlist = cmd_info['cmd_args']['xsce_whitelist']
    whlist = filter(None, whlist) # remove blank lines
    resp = cmd_success(cmd_info['cmd'])
    try:
        stream =  open(squid_whitelist, 'w')
        for item in whlist:       
            stream.write(item + '\n')
    except IOError:
        resp = cmd_error       
    finally:
        stream.close()             
    return (resp)
        
def get_config_vars(cmd_info):
    read_config_vars()
    resp = json.dumps(config_vars)    
    return (resp)
        
def set_config_vars(cmd_info):
    global config_vars
    lock = threading.Lock()
    lock.acquire() # will block if lock is already held
    try:        
        config_vars = cmd_info['cmd_args']['config_vars']        
    finally:
        lock.release() # release lock, no matter what
    write_config_vars()
    #print config_vars
    resp = cmd_success(cmd_info['cmd'])    
    return (resp)                 

def run_ansible(cmd_info):

    global ansible_running_flag    
    global jobs_requested
        
    if ansible_running_flag:
        return ('{"Error": "Ansible Command already Running."}')

    job_command = "/usr/bin/ansible-playbook -i " + xsce_git_path + "/ansible_hosts " + xsce_git_path + "/xsce-from-console.yml --connection=local"

    if 'cmd_args' in cmd_info:
        tags = cmd_info['cmd_args']['tags']
        if tags != "ALL-TAGS":
            job_command += ' --tags="' +  tags +'"'
    else:       
        return cmd_malformed(cmd_info['cmd'])    
    
    resp = request_job(cmd_info, job_command)
    return resp

def reboot_server(cmd_info):    
    resp = cmd_success(cmd_info['cmd'])
    rc = subprocess.call(["/usr/sbin/reboot"])                
    return (resp)
        
def request_job(cmd_info, job_command, cmd_step_no=1):
    global jobs_requested
    job_id = get_job_id()
    
    job_info = {}
    job_info['cmd_rowid'] = cmd_info['cmd_rowid']
    job_info['cmd'] = cmd_info['cmd']
    job_info['cmd_args'] = cmd_info['cmd_args']
        
    job_info['cmd_step_no'] = cmd_step_no
    job_info['job_command'] = job_command    
    job_info['status'] = 'SCHEDULED'
    job_info['status_datetime'] = str(datetime.now())
                
    jobs_requested[job_id] = job_info     
    insert_job(job_id, cmd_info['cmd_rowid'], job_command, cmd_step_no)      
    
    return ('{"Success": "Job  ' + str(job_id) + ' Scheduled."}')

def get_last_jobs_stat(cmd_info):
    conn = sqlite3.connect(xsce_cmdsrv_dbname)
    cur = conn.execute ("SELECT rowid, job_command, job_output, job_status, last_update_datetime FROM jobs ORDER BY rowid DESC LIMIT 30")    
    last_jobs = cur.fetchall()    
    conn.close()

    resp = json.dumps(last_jobs)        
    return resp
    
def get_jobs_running(cmd_info):
    global jobs_running
    today = str(date.today())
    job_stat = {}
    cur_jobs = {}
    for job, job_info in jobs_running.iteritems():
        if today in job_info['status_datetime'] or jobinfo['status'] in ['SCHEDULED','STARTED']:
            job_stat['status'] = job_info['status']
            job_stat['job_command'] = job_info['job_command']
            job_stat['status_datetime'] = job_info['status_datetime']
            job_stat['status_datetime'] = job_info['status_datetime']
            job_stat['job_output'] = job_info['job_output']
            cur_jobs[job] = job_stat
        
    resp = json.dumps(cur_jobs)
    return resp

def json_array(name, str):
    try:
        str_array = str.split('\n')
        str_json = json.dumps(str_array)
        json_resp = '{ "' + name + '":' + str_json + '}'
    except StandardError:
        json_resp = cmd_error()
    return (json_resp)
    
def validate_command(cmd):
    match = re.search('[;,|<>()=&\r\n]', cmd, flags=0)
    if match != None:
        return ('{"Error": "Malformed Command."}')
    else:
        return None
        
def get_cmd_info_key(cmd_info, key):
   if key in cmd_info:
       return (cmd_info[key])
   else:
       return None
      
def cmd_success(cmd):
   return ('{"Success": "Command ' + cmd + '."}')
   
def cmd_error(cmd=None):
    return ('{"Error": "Internal Server Error processing Command ' + cmd + '."}')   

def cmd_malformed(cmd=None):
    return ('{"Error": "Malformed Command ' + cmd + '."}')
    
def insert_command(cmd_msg):
    global last_command_rowid
    lock = threading.Lock()
    lock.acquire() # will block if lock is already held
    try:
        cmd_id = last_command_rowid + 1
        last_command_rowid = cmd_id
    finally:
        lock.release() # release lock, no matter what
    
    now = datetime.now()    
    try:
        conn = sqlite3.connect(xsce_cmdsrv_dbname)
        conn.execute ("INSERT INTO commands (rowid, cmd_msg, create_datetime) VALUES (?,?,?)", (cmd_id, cmd_msg, now))    
        conn.commit()
        conn.close()
                
    except sqlite3.Error, e:
    
        print "Error %s:" % e.args[0]
        log(syslog.LOG_NOTICE, "Sql Lite3 Error %s:" % e.args[0])
    
    finally:
    
        if conn:
            conn.close()        
            
    return (cmd_id)
    
def insert_job(job_id, cmd_rowid, job_command, cmd_step_no=1, job_pid=0, job_output="", job_status="SCHEDULED"):
    print "in insert job"
    now = datetime.now()
        
    conn = sqlite3.connect(xsce_cmdsrv_dbname)
    conn.execute ("INSERT INTO jobs (rowid, cmd_rowid, cmd_step_no, job_command, job_pid, job_output, job_status, create_datetime, last_update_datetime) VALUES (?,?,?,?,?,?,?,?,?)", 
                  (job_id, cmd_rowid, cmd_step_no, job_command, job_pid, job_output, job_status, now, now)) 
                     
    conn.commit() 
    conn.close()   

def upd_job_started(job_id, job_pid, job_status="STARTED"):

    now = datetime.now()
        
    conn = sqlite3.connect(xsce_cmdsrv_dbname)
    conn.execute ("UPDATE jobs SET job_pid = ?, job_status = ?, last_update_datetime = ? WHERE rowid = ?", (job_pid, job_status, now, job_id))
                    
    conn.commit() 
    conn.close()
    
def upd_job_finished(job_id, job_output, job_status="FINISHED"):

    now = datetime.now()
        
    conn = sqlite3.connect(xsce_cmdsrv_dbname)
    conn.execute ("UPDATE jobs SET job_status = ?, job_output = ?, last_update_datetime = ? WHERE rowid = ?", (job_status, job_output, now, job_id))
                    
    conn.commit() 
    conn.close()           
    
def get_job_id():
    global last_job_rowid
    lock = threading.Lock()
    lock.acquire() # will block if lock is already held
    try:
        job_id = last_job_rowid + 1
        last_job_rowid = job_id
    finally:
        lock.release() # release lock, no matter what
        
    return(job_id)        
    
def init():
    global last_command_rowid
    global last_job_rowid
    
    # Read application variables from config files
    app_config()

    # Read vars from ansible file into global vars
    get_xsce_vars()
    
    # Get ansible facts and tags for localhost
    get_ansible_facts()
    get_ansible_tags()    
    
    # See if queue.db exists and create if not
    # Opening a connection creates if not exist
    if not os.path.isfile(xsce_cmdsrv_dbname):
        conn = sqlite3.connect(xsce_cmdsrv_dbname)
        conn.execute ("CREATE TABLE commands (cmd_msg text, create_datetime text)")
        conn.commit()
        conn.execute ("CREATE TABLE jobs (cmd_rowid integer, cmd_step_no integer, job_command text, job_pid integer, job_output blob, job_status text, create_datetime text, last_update_datetime text)")        
        conn.commit()
        conn.close()
    else:
        conn = sqlite3.connect(xsce_cmdsrv_dbname)
        cur = conn.execute("SELECT max (rowid) from commands")
        row = cur.fetchone()
        if row[0] is not None:
            last_command_rowid = row[0]

        cur = conn.execute("SELECT max (rowid) from jobs")
        row = cur.fetchone()
        if row[0] is not None:
            last_job_rowid = row[0]
        
        cur.close()
        conn.close()

def read_config_vars():            
    global config_vars
       
    stream = open("/etc/xsce/config_vars.yml", 'r')
    config_vars = yaml.load(stream)
    stream.close()  
    if config_vars == None:
        config_vars = {} # try to make the ajax call happy
    
def write_config_vars():            
    global config_vars  
    
    lock = threading.Lock()
    lock.acquire() # will block if lock is already held
    
    try:
        stream =  open("/etc/xsce/config_vars.yml", 'w')
        stream.write('# DO NOT MODIFY THIS FILE.\n')
        stream.write('# IT IS AUTOMATICALLY GENERATED.\n')
        for key in config_vars:
             if isinstance(config_vars[key], (int, float)): # boolean is int
                 value = str(config_vars[key])
             else:
                 value = '"' + config_vars[key] + '"'
             entry = key + ': ' + value
             stream.write(entry + '\n')
        stream.close() 
    finally:
        lock.release() # release lock, no matter what    
    
def get_xsce_vars():            
    global default_vars
    global local_vars
    global effective_vars
    
    stream = open(xsce_git_path + "/vars/default_vars.yml", 'r')
    default_vars = yaml.load(stream)
    stream.close()
    
    stream = open(xsce_git_path + "/vars/local_vars.yml", 'r')
    local_vars = yaml.load(stream)
    stream.close()
    
    if local_vars == None:
        local_vars = {}
    
    # combine vars with local taking precedence
    # exclude derived vars marked by {
    
    for key in default_vars:
        if isinstance(default_vars[key], str):
            findpos = default_vars[key].find("{")
            if findpos == -1:
                effective_vars[key] = default_vars[key]
        else:
            effective_vars[key] = default_vars[key]                     
        
    for key in local_vars:
        if isinstance(local_vars[key], str):
            findpos = local_vars[key].find("{")
            if findpos == -1:            
                effective_vars[key] = local_vars[key]       
        else:
            effective_vars[key] = local_vars[key]            
                    
def get_ansible_facts():            
    global ansible_facts
    
    command = "/usr/bin/ansible localhost -i " + xsce_git_path + "/ansible_hosts  -m setup -o  --connection=local"
    args = shlex.split(command) 
    outp = subprocess.check_output(args)
    ans_str = outp.split('success >> ')
    ans = json.loads(ans_str[1])
    ansible_facts = ans['ansible_facts']
    
def get_ansible_tags():            
    global ansible_tags    
    
    command = "/usr/bin/ansible-playbook -i " + xsce_git_path + "/ansible_hosts " + xsce_git_path + "/xsce-from-console.yml --connection=local --tags=???"   
    args = shlex.split(command)
    try:
        subprocess.check_output(args)
    except subprocess.CalledProcessError as e:
        outp = e.output
    
    # get just the tag list and remove final newline
    split = outp.split('values: ')
    ans_tags_str = split[1].split('\n')[0]
    ansible_tags['ansible_tags'] = ans_tags_str
            
def app_config():
    
    global xsce_cmdsrv_path
    global xsce_cmdsrv_pid_file
    global xsce_cmdsrv_dbname
     
    # Read variables from xsce config file 
    read_xsce_conf_file()
    # Read variables from xsce-cmdsrv config file   
    read_xsce_cmdsrv_conf_file()    

    # Compute Derived Variables
    xsce_cmdsrv_path = xsce_base_path + "/xsce_cmdsrv"
    xsce_cmdsrv_pid_file = "/var/run/xsce-cmdsrv.pid"
    xsce_cmdsrv_dbname = xsce_cmdsrv_path + "/xsce_cmdsrv.db"

def read_xsce_cmdsrv_conf_file():
    global cmdsrv_no_workers
    global cmdsrv_job_poll_sleep_interval
    global cmdsrv_max_concurrent_jobs                
    
    stream = open (xsce_cmdsrv_config_file,"r")
    inp = json.load(stream)
    stream.close()
    conf = inp['xsce-cmdsrv_conf']
   
    cmdsrv_no_workers = conf['cmdsrv_no_workers']            
    cmdsrv_job_poll_sleep_interval = conf['cmdsrv_job_poll_sleep_interval']
    cmdsrv_max_concurrent_jobs = conf['cmdsrv_max_concurrent_jobs']
    xsce_cmdsrv_pid_file = conf['xsce_cmdsrv_pid_file']    
    
# These two were taken from the OLPC idmgr application

def read_xsce_conf_file():
    global xsce_base_path
    global xsce_git_path
    
    load_config = {}    
    try:
        f = open(xsce_config_file, "r")
        try:
            for line in f:
                line = line.lstrip()
                if line == '' or line.startswith('#'):
                    continue
                k, v = [x.strip() for x in line.split('=', 1)]
                try:
                    v = float(v)
                    v = int(v)
                except ValueError:
                    pass
                if isinstance(v, str):
                    #Maybe it's quoted.
                    for quote in '\'"':
                        if (v.startswith(quote) and v.endswith(quote)
                            and quote not in v[1:-1]):
                            v = v[1:-1]
                            break
                load_config[k] = v                
        except IOError:            
            load_config = {}
        finally:            
            f.close()
    except IOError:            
        log(syslog.LOG_NOTICE, 'Error reading XSCE Command Server Config')
    else:               
        xsce_base_path = load_config['XSCE_BASE_PATH']
        xsce_git_path = load_config['XSCE_DIR']        

def createDaemon(pidfilename):
    """Detach a process from the controlling terminal and run it in the
    background as a daemon.
    """
    pid = os.fork()
    if (pid == 0):   # The first child.
        pid = os.fork()
        if (pid == 0):   # The second child.
            # Since the current working directory may be a mounted filesystem,
            # we avoid the issue of not being able to unmount the filesystem at
            # shutdown time by changing it to the /opt directory where the cmdsrv is installed.
            os.chdir(xsce_cmdsrv_path)
            #os.umask(config.UMASK)
        else:
            #  write out pid of child
            try:
                pidfile = open( pidfilename, "w" );
                pidfile.write( str( pid ) );
                pidfile.write( "\n" );
                pidfile.close();
            except OSError, e:
                syslog.openlog( 'xsce_cmdsrv', 0, syslog.LOG_USER )
                syslog.syslog( syslog.LOG_ALERT, "Writing PID file: %s [%d]" % (e.strerror, e.errno) )
                syslog.closelog()
                raise
            os._exit(0)  # Exit parent (the first child) of the second child.
    else:
        os._exit(0)# Exit parent of the first child.

    # Close all open file descriptors.
    # Use the getrlimit method to retrieve the maximum file descriptor
    # number that can be opened by this process.  If there is not limit
    # on the resource, use the default value.
    #
    import resource     # Resource usage information.
    maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]
    if (maxfd == resource.RLIM_INFINITY):
        maxfd = MAXFD

    # Iterate through and close all file descriptors.
    for fd in range(0, maxfd):
        try:
            os.close(fd)
        except OSError: # ERROR, fd wasn't open to begin with (ignored)
            pass

    # Redirect the standard I/O file descriptors to the specified file.  Since
    # the daemon has no controlling terminal, most daemons redirect stdin,
    # stdout, and stderr to /dev/null.  This is done to prevent side-effects
    # from reads and writes to the standard I/O file descriptors.

    # This call to open is guaranteed to return the lowest file descriptor,
    # which will be 0 (stdin), since it was closed above.
    os.open(os.devnull, os.O_RDWR)    # standard input (0)

    # Duplicate standard input to standard output and standard error.
    os.dup2(0, 1)# standard output (1)
    os.dup2(0, 2)# standard error (2)
    return(0)    
        
# Now start the application

if __name__ == "__main__":

    # do the UNIX double-fork magic if --daemon passed as argument
    if len(sys.argv) > 1:
        if sys.argv[1] in ('--daemon'):        
           retCode = createDaemon( xsce_cmdsrv_pid_file )
           #retCode = createDaemon( sys.argv[1] ) # pass pid file
        syslog.openlog( 'xsce_cmdsrv', 0, syslog.LOG_USER )
        log = syslog.syslog
    else:
        def log(*args):
            print >> sys.stderr, args
    
    log(syslog.LOG_NOTICE, 'Starting XSCE Command Server')
    
    # Now run the main routine
    main()    
